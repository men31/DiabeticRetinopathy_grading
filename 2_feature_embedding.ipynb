{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c701d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Union\n",
    "\n",
    "from dr_grading.datasets import STL10DataModule, GenericImageDataModule\n",
    "from dr_grading.models import Swin_V2_S, LightningModelWrapper, load_state_from_ckpt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightning as L\n",
    "import torch\n",
    "import h5py\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "StageType = Literal[\"train\", \"val\", \"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f00bf3e",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e5f1be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset_to_hdf5(features, labels, filename):\n",
    "    with h5py.File(filename, \"w\") as f:\n",
    "        f.create_dataset(\"features\", data=features)\n",
    "        f.create_dataset(\"labels\", data=labels)\n",
    "\n",
    "\n",
    "def load_dataset_from_hdf5(filename):\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        features = f[\"features\"][:]\n",
    "        labels = f[\"labels\"][:]\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3abfc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(stage: StageType, image_size: int = 224) -> v2.Compose:\n",
    "    if stage == \"train\":\n",
    "        return v2.Compose(\n",
    "            [\n",
    "                v2.ToImage(),\n",
    "                v2.Resize((image_size, image_size)),\n",
    "                v2.RandomHorizontalFlip(),\n",
    "                v2.RandomApply(torch.nn.ModuleList([\n",
    "                    v2.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "                    v2.GaussianBlur(kernel_size=5, sigma=(0.1, 2.0)),\n",
    "                ]), p=0.3),\n",
    "                v2.RandomAdjustSharpness(2, p=0.4),\n",
    "                v2.RandomAutocontrast(p=0.4),\n",
    "                v2.ToDtype(\n",
    "                    torch.float32, \n",
    "                    scale=True\n",
    "                ),  # Converts and normalizes to [0, 1]\n",
    "            ]\n",
    "        )\n",
    "    else:\n",
    "        return v2.Compose(\n",
    "            [\n",
    "                v2.ToImage(),\n",
    "                v2.Resize((image_size, image_size)),\n",
    "                # FourierTransform(shift=True, return_abs=True),\n",
    "                v2.ToDtype(\n",
    "                    torch.float32, \n",
    "                    scale=True\n",
    "                ),  # Converts and normalizes to [0, 1]\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b92ede89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device(accelerator: Literal[\"auto\", \"gpu\", \"mps\"] = \"auto\") -> torch.device:\n",
    "    # Determine the device based on the accelerator\n",
    "    if accelerator == \"auto\":\n",
    "        device = torch.device(\n",
    "            \"cuda\"\n",
    "            if torch.cuda.is_available()\n",
    "            else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "        )\n",
    "    elif accelerator == \"gpu\" and torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    elif accelerator == \"mps\" and torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    return device\n",
    "\n",
    "\n",
    "def get_dataloader(datamodule: L.LightningDataModule, stage: StageType):\n",
    "    if stage == \"train\":\n",
    "        return datamodule.train_dataloader()\n",
    "    elif stage == \"val\":\n",
    "        return datamodule.val_dataloader()\n",
    "    elif stage == \"test\":\n",
    "        return datamodule.test_dataloader()\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown stage: {stage}\")\n",
    "\n",
    "\n",
    "def get_latent(\n",
    "    model: torch.nn.Module,\n",
    "    datamodule: L.LightningDataModule,\n",
    "    stage: StageType,\n",
    "    epochs: int = 10,\n",
    "    device: Literal[\"auto\", \"gpu\", \"mps\"] = \"auto\",\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Get latent features from the model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to use for feature extraction.\n",
    "        datamodule (L.LightningDataModule): The datamodule containing the dataset.\n",
    "        stage (StageType): The stage of the dataloader ('train', 'validate', 'test').\n",
    "        epochs (int, optional): Number of epochs to run. Defaults to 10.\n",
    "        device (str, optional): The device to use ('auto', 'gpu', 'mps'). Defaults to 'auto'.\n",
    "    \"\"\"\n",
    "    device = get_device(device)\n",
    "    model.to(device)\n",
    "\n",
    "    # Load state from checkpoint if needed\n",
    "    # load_state_from_ckpt(model, ckpt_path)\n",
    "\n",
    "    # Get dataloader\n",
    "    dataloader = get_dataloader(datamodule, stage)\n",
    "\n",
    "    # Set model to evaluation mode and extract features\n",
    "    model.eval()\n",
    "    feature_list = []\n",
    "    label_list = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dataloader, desc=f\"Epochs: {epoch}\", leave=False):\n",
    "                images, labels = batch\n",
    "                images = images.to(device)\n",
    "                outputs = model(images)\n",
    "                feature_list.append(outputs.cpu())\n",
    "                label_list.append(labels)\n",
    "                # Print shapes for debugging\n",
    "                # print(outputs.shape)\n",
    "                # print(labels.shape)\n",
    "        # break\n",
    "    \n",
    "    latent_features = torch.cat(feature_list, dim=0)\n",
    "    labels = torch.cat(label_list, dim=0)\n",
    "\n",
    "    return (latent_features.numpy(), labels.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b93f936",
   "metadata": {},
   "source": [
    "## Extract the APTOS2019 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60f5f7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 5\n",
    "# Get transform\n",
    "train_transform = get_transform(\"train\", image_size=512)\n",
    "test_transform = get_transform(\"test\", image_size=512)\n",
    "\n",
    "# Instantiate datamodule\n",
    "data_dir = r\"D:\\Aj_Aof_Work\\OCT_Disease\\DATASET\\APTOS2019_V4\"\n",
    "datamodule = GenericImageDataModule(\n",
    "    data_dir=data_dir, \n",
    "    batch_size=8, \n",
    "    num_workers=8,\n",
    "    train_transform=train_transform,\n",
    "    test_transform=test_transform,\n",
    "    )\n",
    "datamodule.setup()\n",
    "\n",
    "model = Swin_V2_S(num_classes=num_classes, transfer=True, return_latent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a56d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def FeatureExtraction(\n",
    "#     model: LightningModelWrapper,\n",
    "#     datamodule: L.LightningDataModule,\n",
    "#     stage: StageType = \"train\",\n",
    "#     epochs: int = 10,\n",
    "#     device: Literal[\"auto\", \"gpu\", \"mps\"] = \"auto\",\n",
    "# ) -> None:\n",
    "#     \"\"\"\n",
    "#     Extract features from the model.\n",
    "\n",
    "#     Args:\n",
    "#         model (LightningModelWrapper): The model to use for feature extraction.\n",
    "#         datamodule (L.LightningDataModule): The datamodule containing the dataset.\n",
    "#         stage (StageType, optional): The stage of the dataloader ('train', 'validate', 'test'). Defaults to 'train'.\n",
    "#         epochs (int, optional): Number of epochs to run. Defaults to 10.\n",
    "#         device (str, optional): The device to use ('auto', 'gpu', 'mps'). Defaults to 'auto'.\n",
    "#     \"\"\"\n",
    "#     latent_features, labels = get_latent(model, datamodule, stage, epochs, device)\n",
    "#     save_dataset_to_hdf5(latent_features, labels, f\"{stage}_features.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcf2e895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    }
   ],
   "source": [
    "train_latent_feature, train_labels = get_latent(model, datamodule, stage=\"train\", epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e726e499",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    }
   ],
   "source": [
    "val_latent_feature, val_labels = get_latent(model, datamodule, stage=\"val\", epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da6a505e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    }
   ],
   "source": [
    "test_latent_feature, test_labels = get_latent(model, datamodule, stage=\"test\", epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30e1241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_latent_features(latent_features, labels):\n",
    "    # Convert to DataFrame for easier manipulation\n",
    "    df = pd.DataFrame(latent_features)\n",
    "    df['labels'] = labels\n",
    "    df = df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22403f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = post_process_latent_features(train_latent_feature, train_labels)\n",
    "val_df = post_process_latent_features(val_latent_feature, val_labels)\n",
    "test_df = post_process_latent_features(test_latent_feature, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "580e9c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_csv_hdf5(df, filename):\n",
    "    # Save DataFrame to CSV\n",
    "    df.to_csv(f\"{filename}.csv\", index=False)\n",
    "    # Save DataFrame to HDF5\n",
    "    X = df.drop(columns=['labels']).values\n",
    "    y = df['labels'].values\n",
    "    save_dataset_to_hdf5(X, y, f\"{filename}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61f41e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_csv_hdf5(train_df, \"train\")\n",
    "save_to_csv_hdf5(val_df, \"val\")\n",
    "save_to_csv_hdf5(test_df, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd502e82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
